{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#Build a Classification Model with Spark with a dataset of your choice\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml.recommendation import ALS\n",
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "from pyspark.sql import Row\n",
        "\n",
        "# Initialize Spark Session\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"RecommendationEngine\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "# Try loading from URL first\n",
        "data_url = \"https://raw.githubusercontent.com/apache/spark/master/data/mllib/als/sample_movielens_ratings.txt\"\n",
        "try:\n",
        "    ratings = spark.read.option(\"delimiter\", \"::\").csv(data_url, schema=\"userId int, movieId int, rating float, timestamp long\")\n",
        "    print(\"Loaded data from URL successfully\")\n",
        "except:\n",
        "    # Fallback to sample data if URL fails\n",
        "    print(\"Using sample data as fallback\")\n",
        "    data = [\n",
        "        Row(userId=1, movieId=101, rating=5.0),\n",
        "        Row(userId=1, movieId=102, rating=3.0),\n",
        "        Row(userId=1, movieId=103, rating=2.5),\n",
        "        Row(userId=2, movieId=101, rating=2.0),\n",
        "        Row(userId=2, movieId=102, rating=2.5),\n",
        "        Row(userId=2, movieId=103, rating=5.0),\n",
        "        Row(userId=3, movieId=101, rating=2.5),\n",
        "        Row(userId=3, movieId=104, rating=4.0),\n",
        "        Row(userId=3, movieId=105, rating=4.5)\n",
        "    ]\n",
        "    ratings = spark.createDataFrame(data)\n",
        "\n",
        "# Show the data\n",
        "ratings.show()\n",
        "\n",
        "# Split data into training and test\n",
        "(train, test) = ratings.randomSplit([0.8, 0.2], seed=42)\n",
        "\n",
        "# Build ALS recommendation model\n",
        "als = ALS(\n",
        "    maxIter=5,\n",
        "    regParam=0.01,\n",
        "    userCol=\"userId\",\n",
        "    itemCol=\"movieId\",\n",
        "    ratingCol=\"rating\",\n",
        "    coldStartStrategy=\"drop\",\n",
        "    nonnegative=True,\n",
        "    seed=42\n",
        ")\n",
        "\n",
        "# Train model\n",
        "model = als.fit(train)\n",
        "\n",
        "# Evaluate model\n",
        "predictions = model.transform(test)\n",
        "evaluator = RegressionEvaluator(\n",
        "    metricName=\"rmse\",\n",
        "    labelCol=\"rating\",\n",
        "    predictionCol=\"prediction\"\n",
        ")\n",
        "rmse = evaluator.evaluate(predictions)\n",
        "print(f\"Root-mean-square error = {rmse:.4f}\")\n",
        "\n",
        "# Generate recommendations\n",
        "userRecs = model.recommendForAllUsers(3)\n",
        "movieRecs = model.recommendForAllItems(3)\n",
        "\n",
        "print(\"Top 3 recommendations for users:\")\n",
        "userRecs.show(truncate=False)\n",
        "\n",
        "print(\"Top 3 recommendations for movies:\")\n",
        "movieRecs.show(truncate=False)\n",
        "\n",
        "# Stop Spark session\n",
        "spark.stop()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Ds8ByEbJwIF",
        "outputId": "f356064f-4e34-4cf6-aa4e-52fc4234b146"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using sample data as fallback\n",
            "+------+-------+------+\n",
            "|userId|movieId|rating|\n",
            "+------+-------+------+\n",
            "|     1|    101|   5.0|\n",
            "|     1|    102|   3.0|\n",
            "|     1|    103|   2.5|\n",
            "|     2|    101|   2.0|\n",
            "|     2|    102|   2.5|\n",
            "|     2|    103|   5.0|\n",
            "|     3|    101|   2.5|\n",
            "|     3|    104|   4.0|\n",
            "|     3|    105|   4.5|\n",
            "+------+-------+------+\n",
            "\n",
            "Root-mean-square error = 1.2715\n",
            "Top 3 recommendations for users:\n",
            "+------+------------------------------------------------------+\n",
            "|userId|recommendations                                       |\n",
            "+------+------------------------------------------------------+\n",
            "|1     |[{101, 4.9958506}, {105, 4.3145623}, {104, 3.8351665}]|\n",
            "|2     |[{103, 4.99809}, {101, 2.0000303}, {102, 1.1110015}]  |\n",
            "|3     |[{105, 4.498306}, {104, 3.9984937}, {101, 2.5000443}] |\n",
            "+------+------------------------------------------------------+\n",
            "\n",
            "Top 3 recommendations for movies:\n",
            "+-------+-------------------------------------------------+\n",
            "|movieId|recommendations                                  |\n",
            "+-------+-------------------------------------------------+\n",
            "|101    |[{1, 4.9958506}, {3, 2.5000443}, {2, 2.0000303}] |\n",
            "|102    |[{1, 3.001308}, {3, 1.3686249}, {2, 1.1110015}]  |\n",
            "|103    |[{2, 4.99809}, {1, 3.642063}, {3, 0.7022577}]    |\n",
            "|104    |[{3, 3.9984937}, {1, 3.8351665}, {2, 0.58498895}]|\n",
            "|105    |[{3, 4.498306}, {1, 4.3145623}, {2, 0.6581126}]  |\n",
            "+-------+-------------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Build a Clustering Model with Spark with a dataset of your choice\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml.feature import VectorAssembler, StandardScaler\n",
        "from pyspark.ml.clustering import KMeans\n",
        "from pyspark.ml.evaluation import ClusteringEvaluator\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.sql import Row\n",
        "\n",
        "# Initialize Spark Session\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"ClusteringExample\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "# Try loading from URL first\n",
        "try:\n",
        "    # Using a publicly available Iris dataset URL\n",
        "    data_url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\"\n",
        "    df = spark.read.csv(data_url, header=False, inferSchema=True)\n",
        "\n",
        "    # Add column names manually since the file doesn't have headers\n",
        "    column_names = [\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\", \"species\"]\n",
        "    for i, col_name in enumerate(column_names):\n",
        "        df = df.withColumnRenamed(f\"_c{i}\", col_name)\n",
        "\n",
        "    print(\"Successfully loaded Iris dataset from URL\")\n",
        "except Exception as e:\n",
        "    print(f\"Failed to load from URL: {str(e)}\")\n",
        "    print(\"Using sample data instead\")\n",
        "\n",
        "    # Create sample data\n",
        "    sample_data = [\n",
        "        Row(sepal_length=5.1, sepal_width=3.5, petal_length=1.4, petal_width=0.2, species='Iris-setosa'),\n",
        "        Row(sepal_length=4.9, sepal_width=3.0, petal_length=1.4, petal_width=0.2, species='Iris-setosa'),\n",
        "        Row(sepal_length=7.0, sepal_width=3.2, petal_length=4.7, petal_width=1.4, species='Iris-versicolor'),\n",
        "        Row(sepal_length=6.4, sepal_width=3.2, petal_length=4.5, petal_width=1.5, species='Iris-versicolor'),\n",
        "        Row(sepal_length=6.3, sepal_width=3.3, petal_length=6.0, petal_width=2.5, species='Iris-virginica'),\n",
        "        Row(sepal_length=5.8, sepal_width=2.7, petal_length=5.1, petal_width=1.9, species='Iris-virginica')\n",
        "    ]\n",
        "    df = spark.createDataFrame(sample_data)\n",
        "\n",
        "# Show the data\n",
        "print(\"Data sample:\")\n",
        "df.show(5)\n",
        "\n",
        "# Prepare features (excluding the species column)\n",
        "feature_cols = [c for c in df.columns if c != \"species\"]\n",
        "assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"raw_features\")\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler(inputCol=\"raw_features\", outputCol=\"features\")\n",
        "\n",
        "# Create KMeans model (using k=3 since we know Iris has 3 species)\n",
        "kmeans = KMeans(featuresCol=\"features\", k=3, seed=42)\n",
        "\n",
        "# Create pipeline\n",
        "pipeline = Pipeline(stages=[assembler, scaler, kmeans])\n",
        "\n",
        "# Fit model\n",
        "model = pipeline.fit(df)\n",
        "\n",
        "# Make predictions\n",
        "predictions = model.transform(df)\n",
        "\n",
        "# Evaluate clustering\n",
        "evaluator = ClusteringEvaluator()\n",
        "silhouette = evaluator.evaluate(predictions)\n",
        "print(f\"\\nSilhouette score = {silhouette:.4f}\")\n",
        "\n",
        "# Show cluster centers\n",
        "centers = model.stages[-1].clusterCenters()\n",
        "print(\"\\nCluster Centers:\")\n",
        "for i, center in enumerate(centers):\n",
        "    print(f\"Cluster {i}: {center}\")\n",
        "\n",
        "# Show sample predictions with actual species\n",
        "print(\"\\nSample predictions:\")\n",
        "predictions.select(\"species\", \"prediction\").show(10)\n",
        "\n",
        "# Stop Spark session\n",
        "spark.stop()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TeOjjBsTKVqt",
        "outputId": "a389448b-9e4e-46a5-e468-c9c58e00ea3d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Failed to load from URL: None\n",
            "Using sample data instead\n",
            "Data sample:\n",
            "+------------+-----------+------------+-----------+---------------+\n",
            "|sepal_length|sepal_width|petal_length|petal_width|        species|\n",
            "+------------+-----------+------------+-----------+---------------+\n",
            "|         5.1|        3.5|         1.4|        0.2|    Iris-setosa|\n",
            "|         4.9|        3.0|         1.4|        0.2|    Iris-setosa|\n",
            "|         7.0|        3.2|         4.7|        1.4|Iris-versicolor|\n",
            "|         6.4|        3.2|         4.5|        1.5|Iris-versicolor|\n",
            "|         6.3|        3.3|         6.0|        2.5| Iris-virginica|\n",
            "+------------+-----------+------------+-----------+---------------+\n",
            "only showing top 5 rows\n",
            "\n",
            "\n",
            "Silhouette score = 0.5598\n",
            "\n",
            "Cluster Centers:\n",
            "Cluster 0: [ 8.12207138 11.80646402  2.57653026  1.94817669]\n",
            "Cluster 1: [ 6.18431831 11.86732208  0.71193599  0.21646408]\n",
            "Cluster 2: [7.17380924 9.85900604 2.59348112 2.05640873]\n",
            "\n",
            "Sample predictions:\n",
            "+---------------+----------+\n",
            "|        species|prediction|\n",
            "+---------------+----------+\n",
            "|    Iris-setosa|         1|\n",
            "|    Iris-setosa|         1|\n",
            "|Iris-versicolor|         0|\n",
            "|Iris-versicolor|         0|\n",
            "| Iris-virginica|         0|\n",
            "| Iris-virginica|         2|\n",
            "+---------------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Build a Recommendation Engine with Spark with a dataset of your choice\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "from pyspark.ml.recommendation import ALS\n",
        "from pyspark.sql import Row\n",
        "\n",
        "# Initialize Spark Session\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"RecommendationEngine\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "# Sample data - replace with your dataset\n",
        "data = [\n",
        "    Row(userId=1, movieId=101, rating=5.0),\n",
        "    Row(userId=1, movieId=102, rating=3.0),\n",
        "    Row(userId=1, movieId=103, rating=2.5),\n",
        "    Row(userId=2, movieId=101, rating=2.0),\n",
        "    Row(userId=2, movieId=102, rating=2.5),\n",
        "    Row(userId=2, movieId=103, rating=5.0),\n",
        "    Row(userId=3, movieId=101, rating=2.5),\n",
        "    Row(userId=3, movieId=104, rating=4.0),\n",
        "    Row(userId=3, movieId=105, rating=4.5)\n",
        "]\n",
        "\n",
        "# Create DataFrame\n",
        "ratings = spark.createDataFrame(data)\n",
        "\n",
        "# Split data into training and test\n",
        "(train, test) = ratings.randomSplit([0.8, 0.2], seed=42)\n",
        "\n",
        "# Build ALS recommendation model\n",
        "als = ALS(\n",
        "    maxIter=5,\n",
        "    regParam=0.01,\n",
        "    userCol=\"userId\",\n",
        "    itemCol=\"movieId\",\n",
        "    ratingCol=\"rating\",\n",
        "    coldStartStrategy=\"drop\",\n",
        "    nonnegative=True,\n",
        "    seed=42\n",
        ")\n",
        "\n",
        "# Train model\n",
        "model = als.fit(train)\n",
        "\n",
        "# Evaluate model\n",
        "predictions = model.transform(test)\n",
        "evaluator = RegressionEvaluator(\n",
        "    metricName=\"rmse\",\n",
        "    labelCol=\"rating\",\n",
        "    predictionCol=\"prediction\"\n",
        ")\n",
        "rmse = evaluator.evaluate(predictions)\n",
        "print(f\"Root-mean-square error = {rmse:.4f}\")\n",
        "\n",
        "# Generate top 3 movie recommendations for each user\n",
        "userRecs = model.recommendForAllUsers(3)\n",
        "print(\"Top recommendations:\")\n",
        "userRecs.show(truncate=False)\n",
        "\n",
        "# Generate top 3 user recommendations for each movie\n",
        "movieRecs = model.recommendForAllItems(3)\n",
        "movieRecs.show(truncate=False)\n",
        "\n",
        "# Stop Spark session\n",
        "spark.stop()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UO7XQ-0vKdGk",
        "outputId": "4d8fe183-58cd-4160-fbd5-c663005d715a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Root-mean-square error = 1.2715\n",
            "Top recommendations:\n",
            "+------+------------------------------------------------------+\n",
            "|userId|recommendations                                       |\n",
            "+------+------------------------------------------------------+\n",
            "|1     |[{101, 4.9958506}, {105, 4.3145623}, {104, 3.8351665}]|\n",
            "|2     |[{103, 4.99809}, {101, 2.0000303}, {102, 1.1110015}]  |\n",
            "|3     |[{105, 4.498306}, {104, 3.9984937}, {101, 2.5000443}] |\n",
            "+------+------------------------------------------------------+\n",
            "\n",
            "+-------+-------------------------------------------------+\n",
            "|movieId|recommendations                                  |\n",
            "+-------+-------------------------------------------------+\n",
            "|101    |[{1, 4.9958506}, {3, 2.5000443}, {2, 2.0000303}] |\n",
            "|102    |[{1, 3.001308}, {3, 1.3686249}, {2, 1.1110015}]  |\n",
            "|103    |[{2, 4.99809}, {1, 3.642063}, {3, 0.7022577}]    |\n",
            "|104    |[{3, 3.9984937}, {1, 3.8351665}, {2, 0.58498895}]|\n",
            "|105    |[{3, 4.498306}, {1, 4.3145623}, {2, 0.6581126}]  |\n",
            "+-------+-------------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}